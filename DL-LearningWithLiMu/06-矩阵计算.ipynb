{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 矩阵计算\n",
    "导数是切线的斜率\n",
    "\n",
    "亚导数（类似于偏导数）：将导数拓展到不可微的函数\n",
    "梯度gradient：将导数拓展到向量\n",
    "梯度与等高线正交，方向指向值变化最大的方向，是今后所有机器学习求解的方向\n",
    "## 求导\n",
    "- 标量(1,)对标量(1,)求导，得到一个标量(1,)\n",
    "- 标量(1,)对向量(n, 1)求导，得到一个向量(1, n)（标量对向量中每个元素求导得到新的向量）\n",
    "- 向量(m, 1)对标量(1,)求导，得到一个向量(m, 1)（向量中每个元素对标量求导得到新的向量）\n",
    "- 向量(m, 1)对向量(n, 1)求导，得到一个矩阵(m, n)（=向量y中的每个元素对x向量求导，转化为标量对向量求导，然后转化成一个矩阵=雅可比Jacobi矩阵）\n",
    "- 标量(1,)对矩阵(n, k)求导，得到一个矩阵(k, n)\n",
    "- 矩阵(m, l)对标量(1,)求导，得到一个矩阵(m, l)\n",
    "- 向量(m, 1)对矩阵(n, k)求导，得到(m, k, n)\n",
    "- 矩阵(m, l)对向量(n, 1)求导，得到(m, l, n)\n",
    "- 矩阵(m, l)对矩阵(n, k)求导，得到(m, l, k, n)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
